###############################################################################
groups:

- name: LinuxFreeDiskSpace
  rules:
  - alert: LinuxDiskSpacePercent
    expr: 100*node_filesystem_free_bytes/node_filesystem_size_bytes{fstype="ext4"} < %%monitoring_LinuxDiskSpacePercent_limit%%
    for: %%monitoring_LinuxDiskSpacePercent_time%%
    labels:
      severity: warning
    annotations:
      summary: >-
        {{ $labels.instance }}: Free space on {{ $labels.mountpoint }} == {{ $value }} < %%monitoring_LinuxDiskSpacePercent_limit%% %

  - alert: LinuxDiskSpaceGb
    # Checking only volumes with size >10Gb
    expr: node_filesystem_free_bytes{fstype="ext4"}/1024/1024/1024 < %%monitoring_LinuxDiskSpaceGb_limit%% and node_filesystem_size_bytes{fstype="ext4"} >10*1024*1024*1024
    for: %%monitoring_LinuxDiskSpaceGb_time%%
    labels:
      severity: warning
    annotations:
      summary: >-
        {{ $labels.instance }}: Free space on {{ $labels.mountpoint }} == { ceil($value/1024/1024/1024) } Gb < %%monitoring_LinuxDiskSpaceGb_limit%%Gb

  # Please add ignored mountpoints in node_exporter parameters like
  # "--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|run)($|/)".
  # Same rule using "node_filesystem_free_bytes" will fire when disk fills for non-root users.
  - alert: HostDiskWillFillIn24Hours
    expr: (node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and ON (instance, device, mountpoint) predict_linear(node_filesystem_avail_bytes{fstype!~"tmpfs"}[1h], 24 * 3600) < 0 and node_filesystem_size_bytes{fstype="ext4"} >10*1024*1024*1024
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: >-
        Host disk will fill in 24 hours on instance {{ $labels.instance }} VALUE = {{ $value }}

  - alert: HostOutOfInodes
    expr: node_filesystem_files_free{mountpoint ="/rootfs"} / node_filesystem_files{mountpoint="/rootfs"} * 100 < 10 and ON (instance, device, mountpoint) node_filesystem_readonly{mountpoint="/rootfs"} == 0
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: >-
        Host out of inodes (instance {{ $labels.instance }}) (< 10% left) VALUE = {{ $value }}

  - alert: HostInodesWillFillIn24Hours
    expr: node_filesystem_files_free{mountpoint ="/rootfs"} / node_filesystem_files{mountpoint="/rootfs"} * 100 < 10 and predict_linear(node_filesystem_files_free{mountpoint="/rootfs"}[1h], 24 * 3600) < 0 and ON (instance, device, mountpoint) node_filesystem_readonly{mountpoint="/rootfs"} == 0
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: >-
        Host inodes will fill in 24 hours on instance {{ $labels.instance }} VALUE = {{ $value }}

###############################################################################

- name: LinixDiskIOTime
  rules:
  - alert: LinixDiskIOTimeHigh
    expr: irate(node_disk_io_time_seconds_total [5m]) > %%monitoring_LinixDiskIOTimeHigh_limit%%
    for: %%monitoring_LinixDiskIOTimeHigh_time%%
    labels:
      severity: warning
    annotations:
      summary: >-
        {{ $labels.instance }} : Disk IO Time (/dev/{{ $labels.device }}) == {{ $value }} > %%monitoring_LinixDiskIOTimeHigh_limit%%

###############################################################################

- name: LinixNetwork
  rules:
  - alert: LinixNetworkBandwidthReceiveHigh
    expr:  irate(node_network_receive_bytes_total [5m])*8/1024/1024 > %%monitoring_LinixNetworkBandwidthReceiveHigh_limit%%
    for: %%monitoring_LinixNetworkBandwidthReceiveHigh_time%%
    labels:
      severity: warning
    annotations:
      summary: >-
        {{ $labels.instance }} : Network In (/dev/{{ $labels.device }}) == {{ $value }} Mbit/s > %%monitoring_LinixNetworkBandwidthReceiveHigh_limit%%

  - alert: HostNetworkReceiveErrors
    expr: rate(node_network_receive_errs_total[2m]) / rate(node_network_receive_packets_total[2m]) > 0.01
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: >-
        Host Network Receive Errors on instance {{ $labels.instance }} {{ printf \"%.0f\" $value }} errors in the last two minutes

  - alert: HostNetworkTransmitErrors
    expr: rate(node_network_transmit_errs_total[2m]) / rate(node_network_transmit_packets_total[2m]) > 0.01
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: >-
        Host Network Transmit Errors on instance {{ $labels.instance }} {{ printf \"%.0f\" $value }} errors in the last two minutes

  - alert: HostNetworkInterfaceSaturated
    expr: >-
      (rate(node_network_receive_bytes_total{device!~"^tap.*",device!~"^vnet.*",device!~"^virbr.*",device!~"^veth.*"}[1m]) 
      + rate(node_network_transmit_bytes_total{device!~"^tap.*",device!~"^vnet.*",device!~"^virbr.*",device!~"^veth.*"}[1m])) 
      / node_network_speed_bytes{device!~"^tap.*",device!~"^vnet.*",device!~"^virbr.*"} > 0.8 < 10000
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: >-
        Host Network Interface \"{{ $labels.device }}\" Saturated on instance {{ $labels.instance }} VALUE = {{ $value }}

  - alert: HostConntrackLimit
    expr: node_nf_conntrack_entries / node_nf_conntrack_entries_limit > 0.8
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: >-
        Host conntrack limit is approaching on instance {{ $labels.instance }} VALUE = {{ $value }}

###############################################################################
# Alerts from https://awesome-prometheus-alerts.grep.to/rules#host-and-hardware

- name: LinixMemory
  rules:
  - alert: LinixOutOfMemory
    expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < %%monitoring_LinixOutOfMemory_limit%%
    for: %%monitoring_LinixOutOfMemory_time%%
    labels:
      severity: warning
    annotations:
      summary: >-
        Host out of memory on instance {{ $labels.instance }} (< %%monitoring_LinixOutOfMemory_limit%% % left) VALUE = {{ $value }}

  - alert: HostMemoryUnderMemoryPressure
    expr: rate(node_vmstat_pgmajfault[1m]) > 1000
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: >-
        Host memory under memory pressure on instance {{ $labels.instance }}. High rate of major page faults VALUE = {{ $value }}

  - alert: HostSwapIsFillingUp
    expr: (1 - (node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes)) * 100 > 80
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: >-
        Host swap is filling up on instance {{ $labels.instance }} (>80%) VALUE = {{ $value }}

  - alert: HostOomKillDetected
    expr: increase(node_vmstat_oom_kill[1m]) > 0
    for: 0m
    labels:
      severity: warning
    annotations:
      summary: >-
        Host OOM kill detected on instance {{ $labels.instance }} VALUE = {{ $value }}

###############################################################################

- name: LinixCPU
  rules:
  - alert: HostHighCpuLoad
    expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[2m])) * 100) > %%monitoring_HostHighCpuLoad_limit%%
    for: %%monitoring_HostHighCpuLoad_time%%
    labels:
      severity: warning
    annotations:
      summary: >-
        CPU load on instance {{ $labels.instance }} is > %%monitoring_HostHighCpuLoad_limit%% % (VALUE = {{ $value }})

  - alert: HostCpuStealNoisyNeighbor
    expr: avg by(instance) (rate(node_cpu_seconds_total{mode="steal"}[5m])) * 100 > %%monitoring_HostCpuStealNoisyNeighbor_limit%%
    for: %%monitoring_HostCpuStealNoisyNeighbor_time%%
    labels:
      severity: warning
    annotations:
      summary: >-
        Host CPU steal is > %%monitoring_HostCpuStealNoisyNeighbor_limit%% % ({{ $value }}) on instance {{ $labels.instance }}

  # 1000 context switches is an arbitrary number.
  # Alert threshold depends on nature of application.
  # Please read: https://github.com/samber/awesome-prometheus-alerts/issues/58
  - alert: HostContextSwitching
    expr: (rate(node_context_switches_total[5m])) / (count without(cpu, mode) (node_cpu_seconds_total{mode="idle"})) > %%monitoring_HostContextSwitching_limit%%
    for: %%monitoring_HostContextSwitching_time%%
    labels:
      severity: warning
    annotations:
      summary: >-
        Host context switching on instance {{ $labels.instance }} is {{ $value }} > %%monitoring_HostContextSwitching_limit%%

###############################################################################

- name: LinixSystemD
  rules:
  - alert: HostSystemdServiceCrashed
    expr: node_systemd_unit_state{state="failed"} == 1
    for: 0m
    labels:
      severity: warning
    annotations:
      summary: >-
        Systemd service {{ $labels.name }} crashed on server {{ $labels.instance }}

###############################################################################

- name: LinixHardware
  rules:
  - alert: HostPhysicalComponentTooHot
    expr: node_hwmon_temp_celsius > %%monitoring_HostPhysicalComponentTooHot_limit%%
    for: %%monitoring_HostPhysicalComponentTooHot_time%%
    labels:
      severity: warning
    annotations:
      summary: >-
        Host physical component too hot (instance {{ $labels.instance }}) 
        temp = {{ $value }}C sensor={{ $labels.sensor }} chip={{ $labels.chip }} > %%monitoring_HostPhysicalComponentTooHot_limit%%C

  - alert: HostNodeOvertemperatureAlarm
    expr: node_hwmon_temp_crit_alarm_celsius == 1
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: >-
        Host node overtemperature alarm on instance {{ $labels.instance }} {{ $value }}

  - alert: HostRaidArrayGotInactive
    expr: node_md_state{state="inactive"} > 0
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: >-
        RAID array {{ $labels.device }} is in degraded state on {{ $labels.instance }} (VALUE = {{ $value }})

  - alert: HostRaidDiskFailure
    expr: node_md_disks{state="failed"} > 0
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: >-
        Host RAID disk {{ $labels.md_device }} failure on instance {{ $labels.instance }} VALUE = {{ $value }}

###############################################################################

- name: LinixKernel
  rules:
#  - alert: HostKernelVersionDeviations
#    expr: count(sum(label_replace(node_uname_info, "kernel", "$1", "release", "([0-9]+.[0-9]+.[0-9]+).*")) by (kernel)) > 1
#    for: 6h
#    labels:
#      severity: warning
#    annotations:
#      summary: Host kernel version deviations (instance {{ $labels.instance }})
#      description: "Different kernel versions are running\n  VALUE = {{ $value }}\n"

  - alert: HostEdacCorrectableErrorsDetected
    expr: increase(node_edac_correctable_errors_total[1m]) > 0
    for: 0m
    labels:
      severity: info
    annotations:
      summary: >-
        Host {{ $labels.instance }} has had correctable {{ printf \"%.0f\" $value }} errors in the last minute. VALUE = {{ $value }}

  - alert: HostEdacUncorrectableErrorsDetected
    expr: node_edac_uncorrectable_errors_total > 0
    for: 0m
    labels:
      severity: warning
    annotations:
      summary: >-
        Host {{ $labels.instance }} has had uncorrectable {{ printf \"%.0f\" $value }} errors. VALUE = {{ $value }}

###############################################################################

- name: LinixTime
  rules:
  - alert: HostClockSkew
    expr: (node_timex_offset_seconds > 0.05 and deriv(node_timex_offset_seconds[5m]) >= 0) or (node_timex_offset_seconds < -0.05 and deriv(node_timex_offset_seconds[5m]) <= 0)
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: >-
        Host clock skew on instance {{ $labels.instance }} VALUE = {{ $value }}
